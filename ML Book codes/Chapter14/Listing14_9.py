import tensorflow as tf
import os.path as osp
import numpy as np
from matplotlib import pyplot as plt

samples = np.load(osp.join("regression_data", "reg_samples.npy"))
line_values = np.load(osp.join("regression_data", "reg_line_values.npy"))
sine_values = np.load(osp.join("regression_data", "reg_sine_values.npy"))

series=sine_values

print(samples.shape)

plt.figure()
plt.plot(samples,series)

n_input = 1
time_length=9

ls=len(samples)

dataset=tf.keras.utils.timeseries_dataset_from_array(
    samples[:-1], 
    np.roll(series, -n_input)[:-1], 
    sequence_length=n_input,
    batch_size=time_length,
    end_index=ls-(ls-ls//time_length*time_length),
)

x_train=[]; y_train=[]
for inputs, targets in dataset:
  x_train.append(inputs.numpy())
  y_train.append(targets.numpy())

x_train = np.array(x_train) 
y_train = np.array(y_train)

print(x_train.shape, y_train.shape)

units=10

model = tf.keras.Sequential([
  tf.keras.layers.Input(shape=(time_length,n_input)),  
#  tf.keras.layers.SimpleRNN(units, unroll=True),
#  tf.keras.layers.GRU(units,unroll=True),
#  tf.keras.layers.LSTM(units,unroll=True),
  tf.keras.layers.LSTM(units),  
  tf.keras.layers.Dense(1)
])

model.compile(
  loss=tf.keras.losses.MeanSquaredError(), 
  optimizer=tf.keras.optimizers.Adam(1e-3))

history=model.fit(x_train,y_train, epochs=500, verbose=False)

model.summary()

plt.figure()
plt.xlabel('Epoch Number')
plt.ylabel("Loss")
plt.plot(history.history['loss'])

MODEL_NAME = 'LSTM'
MODEL_DIR = 'models'

model.save(osp.join(MODEL_DIR, MODEL_NAME + '_model_tf'), save_format = "tf")
model.save(osp.join(MODEL_DIR, MODEL_NAME + 'model_keras.h5'), save_format = "h5")

y_pred = model.predict(x_train)

x_t=x_train[:,0,:,:]
x_t = x_t.reshape(-1)

plt.figure()
plt.plot(samples,series)
plt.plot(x_t,y_pred,'r')
plt.show()